{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# import plotly.express as px\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30007, 172)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>...</th>\n",
       "      <th>screensize</th>\n",
       "      <th>uniquenetworklocation</th>\n",
       "      <th>hand</th>\n",
       "      <th>religion</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>voted</th>\n",
       "      <th>married</th>\n",
       "      <th>familysize</th>\n",
       "      <th>major</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>3890</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>2122</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1944</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8118</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>2890</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>4777</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5784</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>4373</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>3242</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>5081</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>6837</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>5521</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>3215</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>7731</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4156</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Psychology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A  Q1I   Q1E  Q2A  Q2I   Q2E  Q3A  Q3I   Q3E  Q4A  ...  screensize  \\\n",
       "0    4   28  3890    4   25  2122    2   16  1944    4  ...           1   \n",
       "1    4    2  8118    1   36  2890    2   35  4777    3  ...           2   \n",
       "2    3    7  5784    1   33  4373    4   41  3242    1  ...           2   \n",
       "3    2   23  5081    3   11  6837    2   37  5521    1  ...           2   \n",
       "4    2   36  3215    2   13  7731    3    5  4156    4  ...           2   \n",
       "\n",
       "   uniquenetworklocation  hand  religion  orientation  race  voted  married  \\\n",
       "0                      1     1        12            1    10      2        1   \n",
       "1                      1     2         7            0    70      2        1   \n",
       "2                      1     1         4            3    60      1        1   \n",
       "3                      1     2         4            5    70      2        1   \n",
       "4                      2     3        10            1    10      2        1   \n",
       "\n",
       "   familysize       major  \n",
       "0           2        None  \n",
       "1           4        None  \n",
       "2           3        None  \n",
       "3           5     biology  \n",
       "4           4  Psychology  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'encuesta.csv', delimiter=r'\\s+', engine='python', on_bad_lines='skip')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separacion de datos en distintos DFs para poder trabajar con ellos\n",
    "\n",
    "preguntas = df.iloc[:, :126]    #Cuestionario del DASS\n",
    "\n",
    "tipi = df.iloc[:, 131:141]      #10-items personality inventory\n",
    "\n",
    "lapse = df.iloc[:, 126:131]     #columna de tiempo que se tarda en responder la encuesta\n",
    "\n",
    "vlc = df.iloc[:, 141:157]       #palabras para evaluación cognitiva, dentro de contexto educativo y de atención al cuestionario\n",
    "\n",
    "demograficos = df.iloc[:, 157:] #datos demográficos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos los Q y nos quedamos con QA que son las respuestas al cuestionario\n",
    "\n",
    "listaA = []\n",
    "for n in range(1, 43):\n",
    "    numero = f'Q{n}I'\n",
    "    listaA.append(numero)\n",
    "QA = preguntas.drop(listaA, axis=1)\n",
    "\n",
    "listaI = []\n",
    "for n in range(1, 43):\n",
    "    numero = f'Q{n}A'\n",
    "    listaI.append(numero)\n",
    "QE = QA.drop(listaI, axis=1)\n",
    "\n",
    "listaE = []\n",
    "for n in range(1, 43):\n",
    "    numero = f'Q{n}E'\n",
    "    listaE.append(numero)\n",
    "QA=QA.drop(listaE,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separarQA(lista,df):\n",
    "    lista_vacia=[]\n",
    "\n",
    "    for n in lista:\n",
    "        numero = f'Q{n}A'\n",
    "        lista_vacia.append(numero)\n",
    "        nuevo_QA=df[lista_vacia]\n",
    "\n",
    "    return nuevo_QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30007, 14) (30007, 14) (30007, 14)\n"
     ]
    }
   ],
   "source": [
    "#Separamos los QA en el tipo de calculo que realizan\n",
    "\n",
    "anxiety_list=[ 2, 4, 7, 9, 15, 19, 20, 23, 25, 28, 30, 36, 40, 41]\n",
    "depression_list=[3, 5, 10, 13, 16, 17, 21, 24, 26, 31, 34, 37, 38, 42]\n",
    "stress_list= [1, 6, 8, 11, 12, 14, 18, 22, 27, 29, 32, 33, 35, 39]\n",
    "\n",
    "Anxiety=separarQA(anxiety_list,QA)\n",
    "Depression=separarQA(depression_list,QA)\n",
    "Stress=separarQA(stress_list,QA)\n",
    "\n",
    "Anxiety.head(2)\n",
    "print(Anxiety.shape,Depression.shape,Stress.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q36A</th>\n",
       "      <th>Q37A</th>\n",
       "      <th>Q38A</th>\n",
       "      <th>Q39A</th>\n",
       "      <th>Q40A</th>\n",
       "      <th>Q41A</th>\n",
       "      <th>Q42A</th>\n",
       "      <th>Suma Estrés</th>\n",
       "      <th>Suma Depresión</th>\n",
       "      <th>Suma Ansiedad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  Q36A  Q37A  Q38A  \\\n",
       "0    4    4    2    4    4    4    4    4    2     1  ...     4     1     2   \n",
       "1    4    1    2    3    4    4    3    4    3     2  ...     3     4     2   \n",
       "\n",
       "   Q39A  Q40A  Q41A  Q42A  Suma Estrés  Suma Depresión  Suma Ansiedad  \n",
       "0     4     3     4     4           40              27             34  \n",
       "1     2     1     2     2           27              24             17  \n",
       "\n",
       "[2 rows x 45 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Añadimos a QA la columna de calculo de estrés/ansiedad/depresión\n",
    "#el cálculo se realiza sumando los valores de las preguntas y restando 14\n",
    "#(el cuestionario debería ser con valores de 0-3, pero al estar de 1-4 hacemos esto para un mejor calculo)\n",
    "# el cálculo se realiza siguiendo las instrucciones de los datos oficiales del inventario de ansiedad de Beck\n",
    "\n",
    "QA['Suma Estrés']=((Stress.sum(axis=1))-14)\n",
    "QA['Suma Depresión']=((Depression.sum(axis=1))-14)\n",
    "QA['Suma Ansiedad']=((Anxiety.sum(axis=1))-14)\n",
    "\n",
    "QA.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valoracion=[]\n",
    "for n in QA['Suma Depresión']:\n",
    "\n",
    "    if n <=9:\n",
    "        valoracion.append('Ninguna')\n",
    "    elif n in range(10,14):\n",
    "        valoracion.append('Muy leve')\n",
    "    elif n in range(14,21):\n",
    "        valoracion.append('Leve / Moderada')\n",
    "    elif n in range(21,28):\n",
    "        valoracion.append('Importante')\n",
    "    elif n >= 28:\n",
    "        valoracion.append('Grave')\n",
    "    else: valoracion.append('Error de conteo')\n",
    "\n",
    "QA['Valoracion Depresión']=(valoracion)\n",
    "\n",
    "\n",
    "\n",
    "valoracion=[]\n",
    "for n in QA['Suma Ansiedad']:\n",
    "\n",
    "    if n <=7:\n",
    "        valoracion.append('Ninguna')\n",
    "    elif n in range(8,10):\n",
    "        valoracion.append('Muy leve')\n",
    "    elif n in range(10,15):\n",
    "        valoracion.append('Leve / Moderada')\n",
    "    elif n in range(15,20):\n",
    "        valoracion.append('Importante')\n",
    "    elif n >= 20:\n",
    "        valoracion.append('Grave')\n",
    "    else: valoracion.append('Error de conteo')\n",
    "\n",
    "QA['Valoracion Ansiedad']=(valoracion)\n",
    "\n",
    "\n",
    "\n",
    "valoracion=[]\n",
    "for n in QA['Suma Estrés']:\n",
    "\n",
    "    if n <=14:\n",
    "        valoracion.append('Ninguna')\n",
    "    elif n in range(15,19):\n",
    "        valoracion.append('Muy leve')\n",
    "    elif n in range(19,26):\n",
    "        valoracion.append('Leve / Moderada')\n",
    "    elif n in range(26,34):\n",
    "        valoracion.append('Importante')\n",
    "    elif n >= 34:\n",
    "        valoracion.append('Grave')\n",
    "    else: valoracion.append('Error de conteo')\n",
    "\n",
    "QA['Valoracion Estrés']=(valoracion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIPI1</th>\n",
       "      <th>TIPI2</th>\n",
       "      <th>TIPI3</th>\n",
       "      <th>TIPI4</th>\n",
       "      <th>TIPI5</th>\n",
       "      <th>TIPI6</th>\n",
       "      <th>TIPI7</th>\n",
       "      <th>TIPI8</th>\n",
       "      <th>TIPI9</th>\n",
       "      <th>TIPI10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TIPI1  TIPI2  TIPI3  TIPI4  TIPI5  TIPI6  TIPI7  TIPI8  TIPI9  TIPI10\n",
       "0      1      5      7      7      7      7      7      5      1       1\n",
       "1      6      5      4      7      5      4      7      7      1       5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=tipi\n",
    "\n",
    "# Invertimos los tipis negativos y calculamos la media de los tipis para cada rasgo de personalidad\n",
    "\n",
    "# df['TIPI6'] = 8 - df['TIPI6']\n",
    "# df['TIPI2'] = 8 - df['TIPI2']\n",
    "# df['TIPI8'] = 8 - df['TIPI8']\n",
    "# df['TIPI4'] = 8 - df['TIPI4']\n",
    "# df['TIPI10'] = 8 - df['TIPI10']\n",
    "\n",
    "# df['Extraversión'] = df[['TIPI1', 'TIPI6']].mean(axis=1)\n",
    "# df['Amabilidad'] = df[['TIPI2', 'TIPI7']].mean(axis=1)\n",
    "# df['Responsabilidad'] = df[['TIPI3', 'TIPI8']].mean(axis=1)\n",
    "# df['Neuroticismo'] = df[['TIPI4', 'TIPI9']].mean(axis=1)\n",
    "# df['Apertura exp'] = df[['TIPI5', 'TIPI10']].mean(axis=1)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 0, 'Psychology', 'Art', 'Business', 'psychology', 'Biology',\n",
       "       'History', 'Education', 'Architecture', nan, 'Marketing',\n",
       "       'Engineering', 'Law', 'English', 'Accounting', 'Dentistry',\n",
       "       'Nursing', 'medicine', 'IT', 'Communication', 'english',\n",
       "       'Economics', 'Physics', 'engineering', 'Finance', 'Science',\n",
       "       'Pharmacy', 'Management', 'law', 'business', 'Medicine',\n",
       "       'Chemistry', 'Medical', 'Mathematics', 'accounting', 'Accountancy',\n",
       "       'Tourism'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conteos = demograficos['major'].value_counts()\n",
    "\n",
    "valores_menos_de_100 = conteos[conteos < 100].index\n",
    "\n",
    "demograficos['major'] = demograficos['major'].apply(lambda x: 0 if x in valores_menos_de_100 else x)\n",
    "\n",
    "demograficos['major'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias = {\n",
    "    'ciencias': ['Biology', 'Physics', 'Chemistry', 'Science', 'Mathematics'],\n",
    "    'medicina': ['Medicine', 'Dentistry', 'Nursing', 'Pharmacy', 'Medical', 'medicine'],\n",
    "    'psicologia': ['Psychology', 'psychology'],\n",
    "    'empresariales': ['Business', 'Marketing', 'Finance', 'Management', 'Accounting', 'accounting', 'Accountancy', 'business'],\n",
    "    'ingenieria': ['Engineering', 'engineering'],\n",
    "    'humanidades': ['History', 'English', 'english', 'Law', 'law', 'Communication'],\n",
    "    'arte': ['Art', 'Architecture'],\n",
    "    'tecnología': ['IT'],\n",
    "    'turismo':['Tourism'],\n",
    "    '0': [None, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inverso_categorias = {}\n",
    "for categoria, valores in categorias.items():\n",
    "    for valor in valores:\n",
    "        inverso_categorias[valor] = categoria\n",
    "\n",
    "# Función de mapeo\n",
    "\n",
    "def mapear_categoria(valor):\n",
    "    return inverso_categorias.get(valor, '0')\n",
    "\n",
    "# Aplicar la función de mapeo\n",
    "\n",
    "demograficos['major'] = demograficos['major'].apply(mapear_categoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>hand</th>\n",
       "      <th>religion</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>voted</th>\n",
       "      <th>married</th>\n",
       "      <th>familysize</th>\n",
       "      <th>major</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>psicologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30002</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>psicologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30003</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30004</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30005</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30006</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>humanidades</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30007 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  engnat  age  \\\n",
       "0        4    4    2    4    4    4    4    4    2     1  ...       2   16   \n",
       "1        4    1    2    3    4    4    3    4    3     2  ...       1   16   \n",
       "2        3    1    4    1    4    3    1    3    2     4  ...       2   17   \n",
       "3        2    3    2    1    3    3    4    2    3     3  ...       1   13   \n",
       "4        2    2    3    4    4    2    4    4    4     3  ...       2   19   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...     ...  ...   \n",
       "30002    2    1    1    1    2    2    1    2    1     1  ...       1   27   \n",
       "30003    3    4    2    2    2    4    4    2    1     3  ...       1   16   \n",
       "30004    2    1    3    2    3    2    1    3    1     4  ...       1   16   \n",
       "30005    3    4    3    4    3    4    4    4    3     4  ...       2   21   \n",
       "30006    3    1    2    2    3    3    3    4    3     1  ...       1   20   \n",
       "\n",
       "       hand  religion  orientation  race  voted  married  familysize  \\\n",
       "0         1        12            1    10      2        1           2   \n",
       "1         2         7            0    70      2        1           4   \n",
       "2         1         4            3    60      1        1           3   \n",
       "3         2         4            5    70      2        1           5   \n",
       "4         3        10            1    10      2        1           4   \n",
       "...     ...       ...          ...   ...    ...      ...         ...   \n",
       "30002     1         4            1    60      1        1           3   \n",
       "30003     1         1            1    70      2        1           3   \n",
       "30004     1         2            4    60      2        1           2   \n",
       "30005     1        10            0    10      2        1           4   \n",
       "30006     1         6            1    60      1        1           2   \n",
       "\n",
       "             major  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4       psicologia  \n",
       "...            ...  \n",
       "30002   psicologia  \n",
       "30003            0  \n",
       "30004            0  \n",
       "30005            0  \n",
       "30006  humanidades  \n",
       "\n",
       "[30007 rows x 87 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba=pd.concat([QA, tipi, vlc, demograficos], axis=1)\n",
    "df_proba=df_proba.drop(['screensize','uniquenetworklocation'],axis=1)\n",
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "\n",
    "df_proba['major']=encoder.fit_transform(df_proba['major'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Q1A', 'Q2A', 'Q3A', 'Q4A', 'Q5A', 'Q6A', 'Q7A', 'Q8A', 'Q9A', 'Q10A',\n",
       "       'Q11A', 'Q12A', 'Q13A', 'Q14A', 'Q15A', 'Q16A', 'Q17A', 'Q18A', 'Q19A',\n",
       "       'Q20A', 'Q21A', 'Q22A', 'Q23A', 'Q24A', 'Q25A', 'Q26A', 'Q27A', 'Q28A',\n",
       "       'Q29A', 'Q30A', 'Q31A', 'Q32A', 'Q33A', 'Q34A', 'Q35A', 'Q36A', 'Q37A',\n",
       "       'Q38A', 'Q39A', 'Q40A', 'Q41A', 'Q42A', 'Suma Estrés', 'Suma Depresión',\n",
       "       'Suma Ansiedad', 'Valoracion Depresión', 'Valoracion Ansiedad',\n",
       "       'Valoracion Estrés', 'TIPI1', 'TIPI2', 'TIPI3', 'TIPI4', 'TIPI5',\n",
       "       'TIPI6', 'TIPI7', 'TIPI8', 'TIPI9', 'TIPI10', 'VCL1', 'VCL2', 'VCL3',\n",
       "       'VCL4', 'VCL5', 'VCL6', 'VCL7', 'VCL8', 'VCL9', 'VCL10', 'VCL11',\n",
       "       'VCL12', 'VCL13', 'VCL14', 'VCL15', 'VCL16', 'education', 'urban',\n",
       "       'gender', 'engnat', 'age', 'hand', 'religion', 'orientation', 'race',\n",
       "       'voted', 'married', 'familysize', 'major'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------ESTRÉS-----------------------------\n",
      "Epoch 1/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.7109 - loss: 0.6388 - val_accuracy: 0.8619 - val_loss: 0.3179\n",
      "Epoch 2/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.8781 - loss: 0.2879 - val_accuracy: 0.9296 - val_loss: 0.1818\n",
      "Epoch 3/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9053 - loss: 0.2210 - val_accuracy: 0.9385 - val_loss: 0.1502\n",
      "Epoch 4/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9224 - loss: 0.1841 - val_accuracy: 0.8870 - val_loss: 0.2299\n",
      "Epoch 5/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9358 - loss: 0.1590 - val_accuracy: 0.8866 - val_loss: 0.2377\n",
      "Epoch 6/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9387 - loss: 0.1461 - val_accuracy: 0.9443 - val_loss: 0.1232\n",
      "Epoch 7/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9359 - loss: 0.1629 - val_accuracy: 0.9483 - val_loss: 0.1219\n",
      "Epoch 8/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9496 - loss: 0.1297 - val_accuracy: 0.8090 - val_loss: 0.5013\n",
      "Epoch 9/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9459 - loss: 0.1266 - val_accuracy: 0.9441 - val_loss: 0.1461\n",
      "Epoch 10/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9600 - loss: 0.1026 - val_accuracy: 0.9553 - val_loss: 0.1201\n",
      "Epoch 11/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9639 - loss: 0.0888 - val_accuracy: 0.9871 - val_loss: 0.0576\n",
      "Epoch 12/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9682 - loss: 0.0843 - val_accuracy: 0.9881 - val_loss: 0.0404\n",
      "Epoch 13/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9672 - loss: 0.0899 - val_accuracy: 0.8948 - val_loss: 0.2522\n",
      "Epoch 14/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9654 - loss: 0.0880 - val_accuracy: 0.9800 - val_loss: 0.0484\n",
      "Epoch 15/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9725 - loss: 0.0730 - val_accuracy: 0.9616 - val_loss: 0.1043\n",
      "Epoch 16/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9693 - loss: 0.0839 - val_accuracy: 0.9632 - val_loss: 0.0878\n",
      "Epoch 17/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9794 - loss: 0.0565 - val_accuracy: 0.9792 - val_loss: 0.0646\n",
      "Epoch 18/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9789 - loss: 0.0589 - val_accuracy: 0.9684 - val_loss: 0.0843\n",
      "Epoch 19/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9790 - loss: 0.0614 - val_accuracy: 0.9695 - val_loss: 0.0575\n",
      "Epoch 20/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0499 - val_accuracy: 0.9647 - val_loss: 0.0724\n",
      "Epoch 21/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9832 - loss: 0.0462 - val_accuracy: 0.9560 - val_loss: 0.0962\n",
      "Epoch 22/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.0444 - val_accuracy: 0.9162 - val_loss: 0.4253\n",
      "Epoch 23/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9743 - loss: 0.0765 - val_accuracy: 0.9967 - val_loss: 0.0184\n",
      "Epoch 24/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9816 - loss: 0.0696 - val_accuracy: 0.9929 - val_loss: 0.0257\n",
      "Epoch 25/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9795 - loss: 0.0631 - val_accuracy: 0.9549 - val_loss: 0.1009\n",
      "Epoch 26/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9796 - loss: 0.0573 - val_accuracy: 0.9960 - val_loss: 0.0187\n",
      "Epoch 27/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9803 - loss: 0.0492 - val_accuracy: 0.9952 - val_loss: 0.0160\n",
      "Epoch 28/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9838 - loss: 0.0446 - val_accuracy: 0.9933 - val_loss: 0.0333\n",
      "Epoch 29/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9791 - loss: 0.0619 - val_accuracy: 0.9983 - val_loss: 0.0064\n",
      "Epoch 30/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0204 - val_accuracy: 0.9953 - val_loss: 0.0154\n",
      "Epoch 31/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.0347 - val_accuracy: 0.9973 - val_loss: 0.0139\n",
      "Epoch 32/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0034 - val_accuracy: 0.9532 - val_loss: 0.1086\n",
      "Epoch 33/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9786 - loss: 0.0560 - val_accuracy: 0.9969 - val_loss: 0.0117\n",
      "Epoch 34/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 0.9995 - val_loss: 0.0034\n",
      "Epoch 35/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9771 - val_loss: 0.0631\n",
      "Epoch 36/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9736 - loss: 0.0682 - val_accuracy: 0.9973 - val_loss: 0.0209\n",
      "Epoch 37/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0399 - val_accuracy: 0.9617 - val_loss: 0.0820\n",
      "Epoch 38/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9909 - loss: 0.0313 - val_accuracy: 0.9495 - val_loss: 0.1120\n",
      "Epoch 39/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.9906 - loss: 0.0332 - val_accuracy: 0.9992 - val_loss: 0.0036\n",
      "Epoch 40/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0368 - val_accuracy: 0.9993 - val_loss: 0.0022\n",
      "Epoch 41/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0107 - val_accuracy: 0.9587 - val_loss: 0.1038\n",
      "Epoch 42/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9767 - loss: 0.0696 - val_accuracy: 0.9825 - val_loss: 0.0401\n",
      "Epoch 43/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9870 - loss: 0.0371 - val_accuracy: 0.9444 - val_loss: 0.2397\n",
      "Epoch 44/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9784 - loss: 0.0695 - val_accuracy: 0.9883 - val_loss: 0.0353\n",
      "Epoch 45/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9899 - loss: 0.0300 - val_accuracy: 0.9988 - val_loss: 0.0078\n",
      "Epoch 46/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.9926 - loss: 0.0235 - val_accuracy: 0.9955 - val_loss: 0.0171\n",
      "Epoch 47/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.0210 - val_accuracy: 0.9988 - val_loss: 0.0058\n",
      "Epoch 48/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9987 - loss: 0.0051 - val_accuracy: 0.9087 - val_loss: 0.3019\n",
      "Epoch 49/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0475 - val_accuracy: 0.9979 - val_loss: 0.0135\n",
      "Epoch 50/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0215 - val_accuracy: 0.9099 - val_loss: 0.2537\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9061 - loss: 0.2601\n",
      "Pérdida: 0.2537131607532501, Precisión: 0.9098907113075256\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_stress=df_proba.drop(['Suma Estrés','Suma Depresión', 'Suma Ansiedad', 'Valoracion Depresión', 'Valoracion Ansiedad'],axis=1)\n",
    "\n",
    "normalizador = MinMaxScaler()\n",
    "\n",
    "\n",
    "print('--------------------------ESTRÉS-----------------------------')\n",
    "\n",
    "df_stress['Valoracion Estrés'] = encoder.fit_transform(df_stress['Valoracion Estrés'])\n",
    "\n",
    "X_stress = df_stress.drop('Valoracion Estrés', axis=1)\n",
    "y_stress = df_stress['Valoracion Estrés']\n",
    "\n",
    "X_stress = normalizador.fit_transform(X_stress)\n",
    "joblib.dump(normalizador, 'normalizador_stress.pkl')\n",
    "\n",
    "X_train_stress, X_test_stress, y_train_stress, y_test_stress = train_test_split(X_stress, y_stress, test_size=0.25, random_state=42)\n",
    "\n",
    "y_train_stress = to_categorical(y_train_stress, num_classes=5)\n",
    "y_test_stress = to_categorical(y_test_stress, num_classes=5)\n",
    "\n",
    "model_stress = Sequential()\n",
    "model_stress.add(Input(shape=(X_train_stress.shape[1],)))\n",
    "\n",
    "model_stress.add(Dense(250, activation='relu'))\n",
    "model_stress.add(Dense(225, activation='relu'))\n",
    "model_stress.add(Dense(200, activation='relu'))\n",
    "model_stress.add(Dense(175, activation='relu'))\n",
    "model_stress.add(Dense(150, activation='relu'))\n",
    "model_stress.add(Dense(125, activation='relu'))\n",
    "model_stress.add(Dense(100, activation='relu'))\n",
    "model_stress.add(Dense(75, activation='relu'))\n",
    "model_stress.add(Dense(50, activation='relu'))\n",
    "model_stress.add(Dense(25, activation='relu'))\n",
    "model_stress.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model_stress.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_stress.fit(X_train_stress,\n",
    "                y_train_stress,\n",
    "                validation_data = (X_test_stress, y_test_stress), \n",
    "                epochs=50, \n",
    "                batch_size=32)\n",
    "\n",
    "loss, accuracy = model_stress.evaluate(X_test_stress, y_test_stress)\n",
    "\n",
    "print(f\"Pérdida: {loss}, Precisión: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------ANSIEDAD-----------------------------\n",
      "Epoch 1/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.7787 - loss: 0.5340 - val_accuracy: 0.8772 - val_loss: 0.2835\n",
      "Epoch 2/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9180 - loss: 0.1985 - val_accuracy: 0.8128 - val_loss: 0.5458\n",
      "Epoch 3/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9182 - loss: 0.1991 - val_accuracy: 0.9564 - val_loss: 0.1037\n",
      "Epoch 4/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9410 - loss: 0.1474 - val_accuracy: 0.9385 - val_loss: 0.1368\n",
      "Epoch 5/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9520 - loss: 0.1213 - val_accuracy: 0.9733 - val_loss: 0.0723\n",
      "Epoch 6/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9499 - loss: 0.1309 - val_accuracy: 0.9688 - val_loss: 0.0766\n",
      "Epoch 7/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9594 - loss: 0.1096 - val_accuracy: 0.8635 - val_loss: 0.3449\n",
      "Epoch 8/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9646 - loss: 0.0898 - val_accuracy: 0.9525 - val_loss: 0.1027\n",
      "Epoch 9/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9712 - loss: 0.0725 - val_accuracy: 0.9203 - val_loss: 0.2384\n",
      "Epoch 10/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9731 - loss: 0.0714 - val_accuracy: 0.9146 - val_loss: 0.1828\n",
      "Epoch 11/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9787 - loss: 0.0584 - val_accuracy: 0.9871 - val_loss: 0.0341\n",
      "Epoch 12/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9735 - loss: 0.0734 - val_accuracy: 0.9521 - val_loss: 0.1383\n",
      "Epoch 13/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9788 - loss: 0.0576 - val_accuracy: 0.9461 - val_loss: 0.1474\n",
      "Epoch 14/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9755 - loss: 0.0653 - val_accuracy: 0.9769 - val_loss: 0.0619\n",
      "Epoch 15/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9801 - loss: 0.0502 - val_accuracy: 0.9901 - val_loss: 0.0309\n",
      "Epoch 16/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9844 - loss: 0.0425 - val_accuracy: 0.9861 - val_loss: 0.0373\n",
      "Epoch 17/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9755 - loss: 0.0905 - val_accuracy: 0.9853 - val_loss: 0.0293\n",
      "Epoch 18/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9868 - loss: 0.0375 - val_accuracy: 0.9965 - val_loss: 0.0124\n",
      "Epoch 19/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9872 - loss: 0.0382 - val_accuracy: 0.9880 - val_loss: 0.0237\n",
      "Epoch 20/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9877 - loss: 0.0384 - val_accuracy: 0.9971 - val_loss: 0.0147\n",
      "Epoch 21/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9905 - loss: 0.0279 - val_accuracy: 0.9989 - val_loss: 0.0089\n",
      "Epoch 22/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0231 - val_accuracy: 0.9992 - val_loss: 0.0046\n",
      "Epoch 23/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9917 - loss: 0.0349 - val_accuracy: 0.9665 - val_loss: 0.0757\n",
      "Epoch 24/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9768 - loss: 0.0802 - val_accuracy: 0.8762 - val_loss: 0.6851\n",
      "Epoch 25/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9845 - loss: 0.0598 - val_accuracy: 0.9665 - val_loss: 0.0792\n",
      "Epoch 26/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0379 - val_accuracy: 0.9979 - val_loss: 0.0132\n",
      "Epoch 27/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.0169 - val_accuracy: 0.9995 - val_loss: 0.0030\n",
      "Epoch 28/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.2489e-04 - val_accuracy: 0.9999 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.1999e-05 - val_accuracy: 0.9999 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.5921e-06 - val_accuracy: 0.9999 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.2575e-07 - val_accuracy: 0.9999 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.0858e-07 - val_accuracy: 0.9999 - val_loss: 0.0014\n",
      "Epoch 33/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.9453e-07 - val_accuracy: 0.9999 - val_loss: 0.0015\n",
      "Epoch 34/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.4147e-07 - val_accuracy: 0.9999 - val_loss: 0.0015\n",
      "Epoch 35/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.1452e-08 - val_accuracy: 0.9999 - val_loss: 0.0016\n",
      "Epoch 36/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.9507 - loss: 0.2107 - val_accuracy: 0.9985 - val_loss: 0.0073\n",
      "Epoch 37/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.9756 - loss: 0.0872 - val_accuracy: 0.9987 - val_loss: 0.0082\n",
      "Epoch 38/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0099 - val_accuracy: 0.9993 - val_loss: 0.0036\n",
      "Epoch 39/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9805 - loss: 0.0611 - val_accuracy: 0.9996 - val_loss: 0.0029\n",
      "Epoch 40/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9845 - loss: 0.0555 - val_accuracy: 0.9749 - val_loss: 0.0427\n",
      "Epoch 41/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0114 - val_accuracy: 0.9997 - val_loss: 0.0020\n",
      "Epoch 42/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0051 - val_accuracy: 0.9859 - val_loss: 0.0349\n",
      "Epoch 43/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 1.0553e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.4451e-05 - val_accuracy: 1.0000 - val_loss: 4.6338e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.5990e-05 - val_accuracy: 1.0000 - val_loss: 3.1480e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.1695e-06 - val_accuracy: 1.0000 - val_loss: 1.7839e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.9181e-06 - val_accuracy: 1.0000 - val_loss: 2.6149e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.0538e-06 - val_accuracy: 1.0000 - val_loss: 1.0744e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.3678e-06 - val_accuracy: 1.0000 - val_loss: 1.1977e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.7244e-07 - val_accuracy: 1.0000 - val_loss: 7.8201e-06\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.9605e-06\n",
      "\n",
      "\n",
      "Pérdida: 7.82010374678066e-06, Precisión: 1.0\n"
     ]
    }
   ],
   "source": [
    "df_anxiety=df_proba.drop(['Suma Depresión','Suma Ansiedad', 'Suma Estrés', 'Valoracion Depresión', 'Valoracion Estrés'],axis=1)\n",
    "\n",
    "normalizador = MinMaxScaler()\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "print('--------------------------ANSIEDAD-----------------------------')\n",
    "\n",
    "df_anxiety['Valoracion Ansiedad'] = encoder.fit_transform(df_anxiety['Valoracion Ansiedad'])\n",
    "\n",
    "X_anxiety = df_anxiety.drop('Valoracion Ansiedad', axis=1)\n",
    "y_anxiety = df_anxiety['Valoracion Ansiedad']\n",
    "\n",
    "X_anxiety = normalizador.fit_transform(X_anxiety)\n",
    "\n",
    "X_train_anxiety, X_test_anxiety, y_train_anxiety, y_test_anxiety = train_test_split(X_anxiety, y_anxiety, test_size=0.25, random_state=42)\n",
    "\n",
    "y_train_anxiety = to_categorical(y_train_anxiety, num_classes=5)\n",
    "y_test_anxiety = to_categorical(y_test_anxiety, num_classes=5)\n",
    "\n",
    "model_anxiety = Sequential()\n",
    "model_anxiety.add(Input(shape=(X_train_anxiety.shape[1],)))\n",
    "\n",
    "model_anxiety.add(Dense(250, activation='relu'))\n",
    "model_anxiety.add(Dense(225, activation='relu'))\n",
    "model_anxiety.add(Dense(200, activation='relu'))\n",
    "model_anxiety.add(Dense(175, activation='relu'))\n",
    "model_anxiety.add(Dense(150, activation='relu'))\n",
    "model_anxiety.add(Dense(125, activation='relu'))\n",
    "model_anxiety.add(Dense(100, activation='relu'))\n",
    "model_anxiety.add(Dense(75, activation='relu'))\n",
    "model_anxiety.add(Dense(50, activation='relu'))\n",
    "model_anxiety.add(Dense(25, activation='relu'))\n",
    "model_anxiety.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model_anxiety.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_anxiety.fit(X_train_anxiety, \n",
    "                  y_train_anxiety, \n",
    "                  epochs=50, \n",
    "                  validation_data = (X_test_anxiety, y_test_anxiety), \n",
    "                  batch_size=32)\n",
    "\n",
    "loss, accuracy = model_anxiety.evaluate(X_test_anxiety, y_test_anxiety)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"Pérdida: {loss}, Precisión: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------DEPRESIÓN-----------------------------\n",
      "Epoch 1/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.7814 - loss: 0.5059 - val_accuracy: 0.9211 - val_loss: 0.1930\n",
      "Epoch 2/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9131 - loss: 0.2093 - val_accuracy: 0.9322 - val_loss: 0.1576\n",
      "Epoch 3/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9275 - loss: 0.1686 - val_accuracy: 0.9408 - val_loss: 0.1514\n",
      "Epoch 4/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - accuracy: 0.9362 - loss: 0.1582 - val_accuracy: 0.9528 - val_loss: 0.1224\n",
      "Epoch 5/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9412 - loss: 0.1453 - val_accuracy: 0.9544 - val_loss: 0.1051\n",
      "Epoch 6/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9517 - loss: 0.1184 - val_accuracy: 0.9499 - val_loss: 0.1462\n",
      "Epoch 7/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.9515 - loss: 0.1176 - val_accuracy: 0.9473 - val_loss: 0.1243\n",
      "Epoch 8/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.9547 - loss: 0.1102 - val_accuracy: 0.9632 - val_loss: 0.0824\n",
      "Epoch 9/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9625 - loss: 0.0920 - val_accuracy: 0.9187 - val_loss: 0.1799\n",
      "Epoch 10/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9644 - loss: 0.0904 - val_accuracy: 0.9182 - val_loss: 0.1663\n",
      "Epoch 11/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9656 - loss: 0.0912 - val_accuracy: 0.9336 - val_loss: 0.1765\n",
      "Epoch 12/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9752 - loss: 0.0652 - val_accuracy: 0.9639 - val_loss: 0.0855\n",
      "Epoch 13/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9717 - loss: 0.0754 - val_accuracy: 0.9828 - val_loss: 0.0470\n",
      "Epoch 14/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9796 - loss: 0.0567 - val_accuracy: 0.9721 - val_loss: 0.0700\n",
      "Epoch 15/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9761 - loss: 0.0588 - val_accuracy: 0.9760 - val_loss: 0.0574\n",
      "Epoch 16/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9786 - loss: 0.0542 - val_accuracy: 0.9803 - val_loss: 0.0542\n",
      "Epoch 17/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9800 - loss: 0.0498 - val_accuracy: 0.9871 - val_loss: 0.0383\n",
      "Epoch 18/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9818 - loss: 0.0462 - val_accuracy: 0.9853 - val_loss: 0.0434\n",
      "Epoch 19/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9805 - loss: 0.0533 - val_accuracy: 0.9921 - val_loss: 0.0244\n",
      "Epoch 20/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9790 - loss: 0.0612 - val_accuracy: 0.9956 - val_loss: 0.0212\n",
      "Epoch 21/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9878 - loss: 0.0398 - val_accuracy: 0.9568 - val_loss: 0.1186\n",
      "Epoch 22/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.9873 - loss: 0.0346 - val_accuracy: 0.9637 - val_loss: 0.1348\n",
      "Epoch 23/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9812 - loss: 0.0490 - val_accuracy: 0.9384 - val_loss: 0.1756\n",
      "Epoch 24/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9865 - loss: 0.0355 - val_accuracy: 0.9075 - val_loss: 0.3093\n",
      "Epoch 25/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0461 - val_accuracy: 0.9544 - val_loss: 0.0855\n",
      "Epoch 26/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9904 - loss: 0.0278 - val_accuracy: 0.9971 - val_loss: 0.0108\n",
      "Epoch 27/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9865 - loss: 0.0414 - val_accuracy: 0.9929 - val_loss: 0.0247\n",
      "Epoch 28/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.9757 - loss: 0.0769 - val_accuracy: 0.9607 - val_loss: 0.0929\n",
      "Epoch 29/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9881 - loss: 0.0398 - val_accuracy: 0.9977 - val_loss: 0.0133\n",
      "Epoch 30/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9892 - loss: 0.0346 - val_accuracy: 0.9969 - val_loss: 0.0094\n",
      "Epoch 31/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9902 - loss: 0.0262 - val_accuracy: 0.9872 - val_loss: 0.0455\n",
      "Epoch 32/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0281 - val_accuracy: 0.9880 - val_loss: 0.0366\n",
      "Epoch 33/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9912 - loss: 0.0303 - val_accuracy: 0.9932 - val_loss: 0.0174\n",
      "Epoch 34/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9888 - loss: 0.0386 - val_accuracy: 0.9865 - val_loss: 0.0361\n",
      "Epoch 35/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9895 - loss: 0.0300 - val_accuracy: 0.9840 - val_loss: 0.0389\n",
      "Epoch 36/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9965 - loss: 0.0130 - val_accuracy: 0.9967 - val_loss: 0.0117\n",
      "Epoch 37/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9844 - loss: 0.0489 - val_accuracy: 0.9833 - val_loss: 0.0433\n",
      "Epoch 38/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9827 - loss: 0.0481 - val_accuracy: 0.9652 - val_loss: 0.1041\n",
      "Epoch 39/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9825 - loss: 0.0495 - val_accuracy: 0.9779 - val_loss: 0.0483\n",
      "Epoch 40/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9860 - loss: 0.0398 - val_accuracy: 0.9909 - val_loss: 0.0230\n",
      "Epoch 41/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0345 - val_accuracy: 0.9984 - val_loss: 0.0075\n",
      "Epoch 42/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9978 - loss: 0.0095 - val_accuracy: 0.9772 - val_loss: 0.0564\n",
      "Epoch 43/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9902 - loss: 0.0339 - val_accuracy: 0.9977 - val_loss: 0.0087\n",
      "Epoch 44/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9904 - loss: 0.0270 - val_accuracy: 0.9943 - val_loss: 0.0218\n",
      "Epoch 45/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9886 - loss: 0.0331 - val_accuracy: 0.9984 - val_loss: 0.0123\n",
      "Epoch 46/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9957 - loss: 0.0173 - val_accuracy: 0.9975 - val_loss: 0.0192\n",
      "Epoch 47/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.0287 - val_accuracy: 0.9984 - val_loss: 0.0086\n",
      "Epoch 48/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9929 - loss: 0.0294 - val_accuracy: 0.9961 - val_loss: 0.0146\n",
      "Epoch 49/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9954 - loss: 0.0114 - val_accuracy: 0.9821 - val_loss: 0.0462\n",
      "Epoch 50/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9910 - loss: 0.0267 - val_accuracy: 0.9835 - val_loss: 0.0364\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0344\n",
      "\n",
      "\n",
      "Pérdida: 0.0363733284175396, Precisión: 0.9834710955619812\n"
     ]
    }
   ],
   "source": [
    "df_depression=df_proba.drop(['Suma Estrés', 'Suma Ansiedad','Suma Depresión', 'Valoracion Ansiedad', 'Valoracion Estrés'],axis=1)\n",
    "\n",
    "normalizador = MinMaxScaler()\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "print('--------------------------DEPRESIÓN-----------------------------')\n",
    "\n",
    "df_depression['Valoracion Depresión'] = encoder.fit_transform(df_depression['Valoracion Depresión'])\n",
    "\n",
    "X_depression = df_depression.drop('Valoracion Depresión', axis=1)\n",
    "y_depression = df_depression['Valoracion Depresión']\n",
    "\n",
    "X_depression = normalizador.fit_transform(X_depression)\n",
    "\n",
    "X_train_depression, X_test_depression, y_train_depression, y_test_depression = train_test_split(X_depression, y_depression, test_size=0.25, random_state=42)\n",
    "\n",
    "y_train_depression = to_categorical(y_train_depression, num_classes=5)\n",
    "y_test_depression = to_categorical(y_test_depression, num_classes=5)\n",
    "\n",
    "model_depression = Sequential()\n",
    "model_depression.add(Input(shape=(X_train_depression.shape[1],)))\n",
    "\n",
    "model_depression.add(Dense(250, activation='relu'))\n",
    "model_depression.add(Dense(225, activation='relu'))\n",
    "model_depression.add(Dense(200, activation='relu'))\n",
    "model_depression.add(Dense(175, activation='relu'))\n",
    "model_depression.add(Dense(150, activation='relu'))\n",
    "model_depression.add(Dense(125, activation='relu'))\n",
    "model_depression.add(Dense(100, activation='relu'))\n",
    "model_depression.add(Dense(75, activation='relu'))\n",
    "model_depression.add(Dense(50, activation='relu'))\n",
    "model_depression.add(Dense(25, activation='relu'))\n",
    "model_depression.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model_depression.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_depression.fit(X_train_depression, \n",
    "                     y_train_depression, \n",
    "                     epochs=50,\n",
    "                     validation_data = (X_test_depression, y_test_depression), \n",
    "                     batch_size=32)\n",
    "\n",
    "loss, accuracy = model_depression.evaluate(X_test_depression, y_test_depression)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"Pérdida: {loss}, Precisión: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validacion\n",
    "# comprobar columnas en notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n",
      "[1 1 0 2 0 3 4 0 2 2 2 2 2 2 1 3 1 0 2 0 0 3 0 4 1]\n",
      "[1 1 0 2 0 3 4 0 2 2 2 2 2 2 1 3 1 0 2 0 0 3 0 4 1]\n"
     ]
    }
   ],
   "source": [
    "model_depression__ = load_model('model_depression.keras')\n",
    "pred_defect=model_depression__.predict(X_depression)\n",
    "pred = model_depression.predict(X_depression)\n",
    "pred_defect__ = np.argmax(pred_defect, axis=1)\n",
    "pred_ = np.argmax(pred, axis=1)\n",
    "print(pred_[:25])\n",
    "print(pred_defect__[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'respuestas\\respuestas_cuestionario.csv')\n",
    "data_=np.asarray(data)\n",
    "\n",
    "data_ = normalizador.fit_transform(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>engant</th>\n",
       "      <th>age</th>\n",
       "      <th>hand</th>\n",
       "      <th>religion</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>voted</th>\n",
       "      <th>married</th>\n",
       "      <th>familysize</th>\n",
       "      <th>major</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...  engant  age  hand  religion  \\\n",
       "0   0   0   0   0   0   0   0   0   0    0  ...       1   25     1         1   \n",
       "1   3   3   3   3   3   3   3   3   3    3  ...       1   25     1         1   \n",
       "\n",
       "   orientation  race  voted  married  familysize  major  \n",
       "0            1     1      1        1           1      1  \n",
       "1            1     1      1        1           1      1  \n",
       "\n",
       "[2 rows x 81 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>hand</th>\n",
       "      <th>religion</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>voted</th>\n",
       "      <th>married</th>\n",
       "      <th>familysize</th>\n",
       "      <th>major</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  engnat  age  hand  \\\n",
       "0    4    4    2    4    4    4    4    4    2     1  ...       2   16     1   \n",
       "1    4    1    2    3    4    4    3    4    3     2  ...       1   16     2   \n",
       "2    3    1    4    1    4    3    1    3    2     4  ...       2   17     1   \n",
       "3    2    3    2    1    3    3    4    2    3     3  ...       1   13     2   \n",
       "4    2    2    3    4    4    2    4    4    4     3  ...       2   19     3   \n",
       "\n",
       "   religion  orientation  race  voted  married  familysize  major  \n",
       "0        12            1    10      2        1           2      0  \n",
       "1         7            0    70      2        1           4      0  \n",
       "2         4            3    60      1        1           3      0  \n",
       "3         4            5    70      2        1           5      0  \n",
       "4        10            1    10      2        1           4      7  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n",
      "[4 0 0]\n",
      "[4 2 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_defect=model_depression__.predict(data)\n",
    "pred = model_depression.predict(data)\n",
    "pred_defect__ = np.argmax(pred_defect, axis=1)\n",
    "pred_ = np.argmax(pred, axis=1)\n",
    "print(pred_)\n",
    "print(pred_defect__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>engant</th>\n",
       "      <th>age</th>\n",
       "      <th>hand</th>\n",
       "      <th>religion</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>voted</th>\n",
       "      <th>married</th>\n",
       "      <th>familysize</th>\n",
       "      <th>major</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...  engant  age  hand  religion  \\\n",
       "0   0   0   0   0   0   0   0   0   0    0  ...       1   25     1         1   \n",
       "1   3   3   3   3   3   3   3   3   3    3  ...       1   25     1         1   \n",
       "2   3   3   3   3   3   3   3   3   3    3  ...       1   25     1         1   \n",
       "\n",
       "   orientation  race  voted  married  familysize  major  \n",
       "0            1     1      1        1           1      1  \n",
       "1            1     1      1        1           1      1  \n",
       "2            1     1      1        1           1      1  \n",
       "\n",
       "[3 rows x 81 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stress.save('model_stress_new.keras')\n",
    "model_anxiety.save('model_anxiety_new.keras')\n",
    "model_depression.save('model_depression_new.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 941 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025879CD3380> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
      "[1 1 0 2 0 3 4 0 2 2 2 2 2 2 1 3 1 0 2 0 0 3 0 4 1]\n",
      "[1 1 0 2 0 3 4 0 2 2 2 2 2 2 1 3 1 0 2 0 0 3 0 4 1]\n"
     ]
    }
   ],
   "source": [
    "model_depression__ = load_model('model_depression_new.keras')\n",
    "pred_defect=model_depression__.predict(X_depression)\n",
    "pred = model_depression.predict(X_depression)\n",
    "pred_defect__ = np.argmax(pred_defect, axis=1)\n",
    "pred_ = np.argmax(pred, axis=1)\n",
    "print(pred_[:25])\n",
    "print(pred_defect__[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "[4 0 0]\n",
      "[4 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_defect=model_depression__.predict(data)\n",
    "pred = model_depression.predict(data)\n",
    "pred_defect__ = np.argmax(pred_defect, axis=1)\n",
    "pred_ = np.argmax(pred, axis=1)\n",
    "print(pred_)\n",
    "print(pred_defect__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
